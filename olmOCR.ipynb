{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import base64\n",
    "import urllib.request\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "import json, re, ast, tempfile\n",
    "import pandas as pd\n",
    "import dspy\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from olmocr.data.renderpdf import render_pdf_to_base64png\n",
    "from olmocr.prompts import build_finetuning_prompt\n",
    "from olmocr.prompts.anchor import get_anchor_text\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_file(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def resize_encode_image(image_path, min_pixels, max_pixels):\n",
    "\n",
    "\n",
    "    if not isinstance(image_path, str):\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf.write(image_path)\n",
    "            image_path = temp_pdf.name\n",
    "            \n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "    \n",
    "    # Calculate the total number of pixels\n",
    "    total_pixels = width * height\n",
    "\n",
    "    # If the image is already within the range, save it as is\n",
    "    if total_pixels <= max_pixels:\n",
    "        print(f\"The image {image_path} is already within the range ({width}x{height}).\")\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    else:\n",
    "        scale_factor = (max_pixels / total_pixels) ** 0.5  # Downscale the image\n",
    "\n",
    "    # Compute the new dimensions\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "\n",
    "    # Resize the image while maintaining the aspect ratio\n",
    "    resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "    #resized_img.save(\"test.png\")\n",
    "    img_bytes = BytesIO()\n",
    "    resized_img.save(img_bytes, format=\"PNG\")  # Save as JPEG (change if needed)\n",
    "    img_bytes = img_bytes.getvalue()\n",
    "    \n",
    "    # Encode to Base64\n",
    "    return base64.b64encode(img_bytes).decode('utf-8')\n",
    "\n",
    "def encode_pdf(path: str, page_indexes: tuple = None):\n",
    "\n",
    "    if not isinstance(image_path):\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf.write(path)\n",
    "            path = temp_pdf.name\n",
    "\n",
    "    reader = PdfReader(path)\n",
    "    pages_base64 = []\n",
    "    num_pages = len(reader.pages)\n",
    "    # If pages is None, process all pages\n",
    "    if page_indexes is None:\n",
    "        page_indexes = range(num_pages)  # Default: all pages\n",
    "    \n",
    "    for i in tqdm(page_indexes):\n",
    "        pages_base64.append(render_pdf_to_base64png(path, i, target_longest_image_dim=1024))\n",
    "\n",
    "    return pages_base64\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.set_device(1)\n",
    "\n",
    "# Initialize the model\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"allenai/olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16).eval()\n",
    "min_pixels = 256*28*28\n",
    "max_pixels = 1280*28*28\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels, use_fast=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image\n",
    "image_path = 'OCR_menu_example/alligalli_section2.png'\n",
    "#image_base64 = encode_image_file(image_path) #Encode without resize\n",
    "image_base64 = resize_encode_image(image_path, max_pixels=max_pixels, min_pixels=min_pixels) #Encode with resize\n",
    "\n",
    "# PDF\n",
    "#pdf_path = \"OCR_menu_example/menu-gustoal129.pdf\"\n",
    "#image_base64 = encode_pdf(pdf_path, (3,))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_base64 = encode_image_file(\"test.png\")\n",
    "# Build the full prompt\n",
    "messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"\"\"Extract only the menu dishes from the image and provide it as a list\\\n",
    "                     with following fields: name, price, ingredients.\n",
    "                     Try to dectect the section of each dish among the following categories: Antipasti, Primi, Secondi, Contorni, Dolci, Bevande\n",
    "                    If any of these fields are not present use the value None\n",
    "                    DO NOT PROVIDE ANY OTHER INFORMATION\n",
    "                    Example of output: [\n",
    "                        ['Pizza Margherita', '10.0', 'Pomodoro, Mozzarella', \"Secondi\"]\n",
    "                     [\"Pasta al pomodoro\", '8.00', 'Pasta, pomodoro, basilico', \"Primi\"]\n",
    "                     ]\"\"\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"} },\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "\n",
    "# Apply the chat template and processor\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "main_image = Image.open(BytesIO(base64.b64decode(image_base64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory\n",
    "try:\n",
    "    del output\n",
    "    del inputs\n",
    "except:\n",
    "    pass\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[main_image],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.8,\n",
    "            max_new_tokens=8000,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the output\n",
    "prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "new_tokens = output[:, prompt_length:]\n",
    "text_output = processor.tokenizer.batch_decode(\n",
    "    new_tokens, skip_special_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_token = \"\"\n",
    "deep_seek_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_llama = dspy.LM(\"huggingface/meta-llama/Meta-Llama-3-8B-Instruct\", api_key=huggingface_token, cache=False)\n",
    "lm_deepseek = dspy.LM('openai/deepseek-chat', api_key=deep_seek_token, api_base=\"https://api.deepseek.com\", cache=False, max_tokens=8000)\n",
    "lm_ollama = dspy.LM('ollama_chat/qwen2.5:32b', api_base='http://localhost:11434', api_key='', max_tokens=8000, cache=False)\n",
    "dspy.configure(lm=lm_deepseek)\n",
    "\n",
    "#Define a simple signature for basic question answering\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Format this menu into a list readble for pandas dataframe.\n",
    "    The datafram should have tre columns: name, ingridients, price, section\n",
    "    If there is no section, you have to decide the section of each dish among the following categories: Antipasti, Primi, Secondi, Contorni, Dolci, Bevande\n",
    "    The section MUST BE ONE OF THESE: Antipasti, Primi, Secondi, Contorni, Dolci, Bevande\n",
    "    Do not split the dish if it is in the same row\n",
    "    \"\"\"\n",
    "    question = dspy.InputField(desc=\"Raw menu input\")\n",
    "    answer: list = dspy.OutputField(desc=\"should be a list\")\n",
    "\n",
    "generate_formatted_menu = dspy.ChainOfThought(BasicQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_menu = generate_formatted_menu(question=text_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(formatted_menu.answer)\n",
    "pd.DataFrame(formatted_menu.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
