{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import dspy\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "from olmocr.data.renderpdf import render_pdf_to_base64png\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.8)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def encode_image_file(image_path):\n",
    "    # Open the image file in binary read mode\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # Read and encode the image content in base64, then decode to UTF-8 string\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def resize_encode_image(image_path, min_pixels, max_pixels):\n",
    "    # If input is not a string (e.g., file-like object), save it to a temporary file\n",
    "    if not isinstance(image_path, str):\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf.write(image_path)\n",
    "            image_path = temp_pdf.name\n",
    "\n",
    "    # Open the image\n",
    "    img = Image.open(image_path)\n",
    "    width, height = img.size\n",
    "\n",
    "    # Calculate the total number of pixels\n",
    "    total_pixels = width * height\n",
    "\n",
    "    # If the image is already within the allowed pixel range, return its base64 encoding\n",
    "    if total_pixels <= max_pixels:\n",
    "        print(f\"The image {image_path} is already within the range ({width}x{height}).\")\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    else:\n",
    "        # Compute downscaling factor to respect max_pixels\n",
    "        scale_factor = (max_pixels / total_pixels) ** 0.5\n",
    "\n",
    "    # Compute new dimensions preserving aspect ratio\n",
    "    new_width = int(width * scale_factor)\n",
    "    new_height = int(height * scale_factor)\n",
    "\n",
    "    # Resize the image using high-quality filter\n",
    "    resized_img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "\n",
    "    # Save the resized image to an in-memory buffer\n",
    "    img_bytes = BytesIO()\n",
    "    resized_img.save(img_bytes, format=\"PNG\")  # Change format if needed\n",
    "    img_bytes = img_bytes.getvalue()\n",
    "\n",
    "    # Encode to Base64 and return\n",
    "    return base64.b64encode(img_bytes).decode('utf-8')\n",
    "\n",
    "def encode_pdf(path: str, page_indexes: tuple = None):\n",
    "    # Check if input is not a string, save it to a temporary file\n",
    "    if not isinstance(path, str):  # FIXED typo: was checking undefined `image_path`\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf:\n",
    "            temp_pdf.write(path)\n",
    "            path = temp_pdf.name\n",
    "\n",
    "    # Load the PDF\n",
    "    reader = PdfReader(path)\n",
    "    pages_base64 = []\n",
    "    num_pages = len(reader.pages)\n",
    "\n",
    "    # If no page indexes provided, process all\n",
    "    if page_indexes is None:\n",
    "        page_indexes = range(num_pages)\n",
    "\n",
    "    # Render each selected page to image and encode\n",
    "    for i in tqdm(page_indexes):\n",
    "        pages_base64.append(render_pdf_to_base64png(path, i, target_longest_image_dim=1024))\n",
    "\n",
    "    return pages_base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"allenai/olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16\n",
    ").eval()\n",
    "\n",
    "min_pixels = 256 * 28 * 28\n",
    "max_pixels = 1280 * 28 * 28\n",
    "\n",
    "# Initialize processor\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    min_pixels=min_pixels,\n",
    "    max_pixels=max_pixels,\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and encode image\n",
    "image_path = 'OCR_menu_example/alligalli_section2.png'\n",
    "image_base64 = resize_encode_image(image_path, max_pixels=max_pixels, min_pixels=min_pixels\n",
    "                                   \n",
    "# PDF\n",
    "#pdf_path = \"OCR_menu_example/menu-gustoal129.pdf\"\n",
    "#image_base64 = encode_pdf(pdf_path, (3,))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input message\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"\"\"Extract only the menu dishes from the image and provide it as a list\n",
    "             with following fields: name, price, ingredients.\n",
    "             Try to dectect the section of each dish among the following categories: Antipasti, Primi, Secondi, Contorni, Dolci, Bevande\n",
    "            If any of these fields are not present use the value None\n",
    "            DO NOT PROVIDE ANY OTHER INFORMATION\n",
    "            Example of output: [\n",
    "                ['Pizza Margherita', '10.0', 'Pomodoro, Mozzarella', \"Secondi\"]\n",
    "             [\"Pasta al pomodoro\", '8.00', 'Pasta, pomodoro, basilico', \"Primi\"]\n",
    "             ]\"\"\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Prepare prompt\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "main_image = Image.open(BytesIO(base64.b64decode(image_base64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean memory\n",
    "try:\n",
    "    del output\n",
    "    del inputs\n",
    "except:\n",
    "    pass\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess inputs\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[main_image],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = {key: value.to(device) for (key, value) in inputs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run model inference\n",
    "output = model.generate(\n",
    "    **inputs,\n",
    "    temperature=0.8,\n",
    "    max_new_tokens=8000,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the generated tokens\n",
    "prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "new_tokens = output[:, prompt_length:]\n",
    "text_output = processor.tokenizer.batch_decode(\n",
    "    new_tokens, skip_special_tokens=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure language models (select one of the following)\n",
    "huggingface_token = \"\"\n",
    "deep_seek_token = \"\"\n",
    "\n",
    "lm_llama = dspy.LM(\"huggingface/meta-llama/Meta-Llama-3-8B-Instruct\", api_key=huggingface_token, cache=False)\n",
    "lm_deepseek = dspy.LM('openai/deepseek-chat', api_key=deep_seek_token, api_base=\"https://api.deepseek.com\", cache=False, max_tokens=8000)\n",
    "lm_ollama = dspy.LM('ollama_chat/qwen2.5:32b', api_base='http://localhost:11434', api_key='', max_tokens=8000, cache=False)\n",
    "\n",
    "\n",
    "dspy.configure(lm=lm_deepseek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DSPy Signature for parsing menu items\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Format this menu into a list readable for pandas dataframe.\n",
    "    The dataframe should have three columns: name, ingredients, price, section.\n",
    "    If there is no section, assign one from these: Antipasti, Primi, Secondi, Contorni, Dolci, Bevande.\n",
    "    The section MUST BE ONE OF THESE categories.\n",
    "    Do not split a dish if it is on the same row.\n",
    "    \"\"\"\n",
    "    question = dspy.InputField(desc=\"Raw menu input\")\n",
    "    answer: list = dspy.OutputField(desc=\"should be a list\")\n",
    "\n",
    "# Create reasoning chain to format menu\n",
    "generate_formatted_menu = dspy.ChainOfThought(BasicQA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run formatting logic\n",
    "formatted_menu = generate_formatted_menu(question=text_output[0])\n",
    "\n",
    "# %%\n",
    "# Display results\n",
    "pd.DataFrame(formatted_menu.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
